{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majid9418/Breast-Tumor-Classification-Histopathological/blob/main/New_binary_classification_BreakHis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12bLKbD9lx5F",
        "outputId": "e1f30fa0-42d8-4255-9ed1-0cea253271ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzpB68iDiIbj",
        "outputId": "2752ae12-436a-4ddc-ebc6-6ce28d47455c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Found 6327 images belonging to 2 classes.\n",
            "Found 1582 images belonging to 2 classes.\n",
            "{'benign': 1984, 'malignant': 4343}\n",
            "Underrepresented class: ['benign']\n",
            "Found 8311 images belonging to 2 classes.\n",
            "Found 1582 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB5\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# Define base directory\n",
        "base_dir = '/content/drive/MyDrive/breakhis/BreaKHis_v1/histology_slides/breast'\n",
        "\n",
        "# Define subdirectories for benign and malignant\n",
        "benign_dir = os.path.join(base_dir, 'benign')\n",
        "malignant_dir = os.path.join(base_dir, 'malignant')\n",
        "\n",
        "# Create directories for training and validation data\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Create subdirectories for benign and malignant in train and validation folders\n",
        "for category in ['benign', 'malignant']:\n",
        "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, category), exist_ok=True)\n",
        "\n",
        "# Function to split data and copy to respective directories\n",
        "def split_and_copy_images(source_dir, train_dest_dir, val_dest_dir, split_ratio=0.2):\n",
        "    image_files = glob.glob(os.path.join(source_dir, '**', '*.png'), recursive=True)\n",
        "    train_files, val_files = train_test_split(image_files, test_size=split_ratio, random_state=42)\n",
        "\n",
        "    for file in train_files:\n",
        "        shutil.copy(file, train_dest_dir)\n",
        "\n",
        "    for file in val_files:\n",
        "        shutil.copy(file, val_dest_dir)\n",
        "\n",
        "# Split and copy images for benign and malignant\n",
        "split_and_copy_images(benign_dir, os.path.join(train_dir, 'benign'), os.path.join(val_dir, 'benign'))\n",
        "split_and_copy_images(malignant_dir, os.path.join(train_dir, 'malignant'), os.path.join(val_dir, 'malignant'))\n",
        "\n",
        "# General data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.9, 1.1],\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create general data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Calculate the number of images in each class\n",
        "class_counts = {category: len(glob.glob(os.path.join(train_dir, category, '*.png'))) for category in ['benign', 'malignant']}\n",
        "print(class_counts)\n",
        "\n",
        "# Determine underrepresented class\n",
        "mean_count = np.mean(list(class_counts.values()))\n",
        "underrepresented_class = [category for category, count in class_counts.items() if count < mean_count]\n",
        "print(f\"Underrepresented class: {underrepresented_class}\")\n",
        "\n",
        "# Custom augmentation pipeline for underrepresented class\n",
        "aug_pipeline = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Flipud(0.2),\n",
        "    iaa.Affine(rotate=(-45, 45)),\n",
        "    iaa.Multiply((0.8, 1.2)),\n",
        "    iaa.GaussianBlur(sigma=(0.0, 3.0)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.01*255, 0.05*255))\n",
        "])\n",
        "\n",
        "# Augment and add images for underrepresented class\n",
        "for category in underrepresented_class:\n",
        "    category_dir = os.path.join(train_dir, category)\n",
        "    images = glob.glob(os.path.join(category_dir, '*.png'))\n",
        "\n",
        "    for img_path in images:\n",
        "        img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        for _ in range(int(mean_count / len(images))):\n",
        "            aug_images = aug_pipeline(images=img_array.astype(np.uint8))\n",
        "            for aug_img in aug_images:\n",
        "                aug_img_path = os.path.join(category_dir, f\"aug_{os.path.basename(img_path)}\")\n",
        "                aug_img = tf.keras.preprocessing.image.array_to_img(aug_img)\n",
        "                aug_img.save(aug_img_path)\n",
        "\n",
        "# Re-create generators after augmentation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzt6ipcy1_Bm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB5\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import seaborn as sns\n",
        "\n",
        "# Define base directory\n",
        "base_dir = '/content/drive/MyDrive/breakhis/BreaKHis_v1/histology_slides/breast'\n",
        "\n",
        "# Define training and validation directories\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# General data augmentation for binary classification\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.9, 1.1],\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Define the model for binary classification\n",
        "model = Sequential([\n",
        "    EfficientNetB5(input_shape=(224, 224, 3), include_top=False, weights='imagenet'),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.8),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_filepath = '/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n",
        "\n",
        "lr_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=37,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr, lr_callback]\n",
        ")\n",
        "\n",
        "# Load the best model\n",
        "best_model = tf.keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "# Evaluate the best model\n",
        "loss, accuracy = best_model.evaluate(validation_generator, verbose=0)\n",
        "print(f'Validation loss: {loss}, Validation accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "\n",
        "# Generate predictions and compute confusion matrix\n",
        "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
        "y_pred = best_model.predict(validation_generator, steps=validation_steps, verbose=1)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "y_true = validation_generator.classes[:len(y_pred_labels)]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_labels)\n",
        "class_names = ['benign', 'malignant']\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "report = classification_report(y_true, y_pred_labels, target_names=class_names)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bQBsSTAuYcd",
        "outputId": "59d82299-ed40-4bde-b0a2-db266106a57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8311 images belonging to 2 classes.\n",
            "Found 791 images belonging to 2 classes.\n",
            "Found 791 images belonging to 2 classes.\n",
            "Epoch 1/28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.7646 - loss: 0.4942 \n",
            "Epoch 1: val_loss improved from inf to 0.67259, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5274s\u001b[0m 19s/step - accuracy: 0.7649 - loss: 0.4937 - val_accuracy: 0.6865 - val_loss: 0.6726 - learning_rate: 1.0000e-04\n",
            "Epoch 2/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9256 - loss: 0.2002\n",
            "Epoch 2: val_loss improved from 0.67259 to 0.64321, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 1s/step - accuracy: 0.9257 - loss: 0.2001 - val_accuracy: 0.6877 - val_loss: 0.6432 - learning_rate: 1.0000e-04\n",
            "Epoch 3/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9489 - loss: 0.1468\n",
            "Epoch 3: val_loss did not improve from 0.64321\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.9489 - loss: 0.1468 - val_accuracy: 0.7155 - val_loss: 0.7236 - learning_rate: 1.0000e-04\n",
            "Epoch 4/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9643 - loss: 0.1121\n",
            "Epoch 4: val_loss improved from 0.64321 to 0.14115, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.9643 - loss: 0.1121 - val_accuracy: 0.9595 - val_loss: 0.1411 - learning_rate: 1.0000e-04\n",
            "Epoch 5/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9707 - loss: 0.1016\n",
            "Epoch 5: val_loss improved from 0.14115 to 0.09592, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 1s/step - accuracy: 0.9707 - loss: 0.1015 - val_accuracy: 0.9735 - val_loss: 0.0959 - learning_rate: 1.0000e-04\n",
            "Epoch 6/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9741 - loss: 0.0813\n",
            "Epoch 6: val_loss improved from 0.09592 to 0.08350, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 1s/step - accuracy: 0.9741 - loss: 0.0813 - val_accuracy: 0.9747 - val_loss: 0.0835 - learning_rate: 1.0000e-04\n",
            "Epoch 7/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9800 - loss: 0.0677\n",
            "Epoch 7: val_loss did not improve from 0.08350\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 1s/step - accuracy: 0.9800 - loss: 0.0677 - val_accuracy: 0.9646 - val_loss: 0.0984 - learning_rate: 1.0000e-04\n",
            "Epoch 8/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9878 - loss: 0.0530\n",
            "Epoch 8: val_loss did not improve from 0.08350\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.9878 - loss: 0.0530 - val_accuracy: 0.9684 - val_loss: 0.0913 - learning_rate: 1.0000e-04\n",
            "Epoch 9/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9859 - loss: 0.0513\n",
            "Epoch 9: val_loss improved from 0.08350 to 0.07249, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 1s/step - accuracy: 0.9859 - loss: 0.0513 - val_accuracy: 0.9785 - val_loss: 0.0725 - learning_rate: 1.0000e-04\n",
            "Epoch 10/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9909 - loss: 0.0414\n",
            "Epoch 10: val_loss did not improve from 0.07249\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.9909 - loss: 0.0414 - val_accuracy: 0.9772 - val_loss: 0.0803 - learning_rate: 1.0000e-04\n",
            "Epoch 11/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9897 - loss: 0.0421\n",
            "Epoch 11: val_loss improved from 0.07249 to 0.05731, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 1s/step - accuracy: 0.9897 - loss: 0.0421 - val_accuracy: 0.9823 - val_loss: 0.0573 - learning_rate: 9.0484e-05\n",
            "Epoch 12/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9935 - loss: 0.0327\n",
            "Epoch 12: val_loss improved from 0.05731 to 0.05386, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.9935 - loss: 0.0327 - val_accuracy: 0.9874 - val_loss: 0.0539 - learning_rate: 8.1873e-05\n",
            "Epoch 13/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9940 - loss: 0.0286\n",
            "Epoch 13: val_loss did not improve from 0.05386\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 1s/step - accuracy: 0.9940 - loss: 0.0286 - val_accuracy: 0.9735 - val_loss: 0.0864 - learning_rate: 7.4082e-05\n",
            "Epoch 14/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9943 - loss: 0.0284\n",
            "Epoch 14: val_loss improved from 0.05386 to 0.05119, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 1s/step - accuracy: 0.9943 - loss: 0.0284 - val_accuracy: 0.9861 - val_loss: 0.0512 - learning_rate: 6.7032e-05\n",
            "Epoch 15/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9950 - loss: 0.0260\n",
            "Epoch 15: val_loss improved from 0.05119 to 0.04815, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 1s/step - accuracy: 0.9950 - loss: 0.0260 - val_accuracy: 0.9874 - val_loss: 0.0482 - learning_rate: 6.0653e-05\n",
            "Epoch 16/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9950 - loss: 0.0273\n",
            "Epoch 16: val_loss did not improve from 0.04815\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - accuracy: 0.9950 - loss: 0.0273 - val_accuracy: 0.9861 - val_loss: 0.0497 - learning_rate: 5.4881e-05\n",
            "Epoch 17/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9951 - loss: 0.0250\n",
            "Epoch 17: val_loss did not improve from 0.04815\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.9951 - loss: 0.0250 - val_accuracy: 0.9886 - val_loss: 0.0485 - learning_rate: 4.9659e-05\n",
            "Epoch 18/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9968 - loss: 0.0181\n",
            "Epoch 18: val_loss did not improve from 0.04815\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.9968 - loss: 0.0181 - val_accuracy: 0.9874 - val_loss: 0.0496 - learning_rate: 4.4933e-05\n",
            "Epoch 19/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9971 - loss: 0.0169\n",
            "Epoch 19: val_loss improved from 0.04815 to 0.04082, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 1s/step - accuracy: 0.9971 - loss: 0.0169 - val_accuracy: 0.9899 - val_loss: 0.0408 - learning_rate: 4.0657e-05\n",
            "Epoch 20/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9955 - loss: 0.0204\n",
            "Epoch 20: val_loss did not improve from 0.04082\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.9955 - loss: 0.0204 - val_accuracy: 0.9886 - val_loss: 0.0476 - learning_rate: 3.6788e-05\n",
            "Epoch 21/28\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9971 - loss: 0.0161\n",
            "Epoch 21: val_loss did not improve from 0.04082\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - accuracy: 0.9971 - loss: 0.0161 - val_accuracy: 0.9886 - val_loss: 0.0470 - learning_rate: 3.3287e-05\n",
            "Epoch 22/28\n",
            "\u001b[1m225/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.9983 - loss: 0.0136"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB5\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import seaborn as sns\n",
        "\n",
        "# Define base directory\n",
        "base_dir = '/content/drive/MyDrive/breakhis/BreaKHis_v1/histology_slides/breast'\n",
        "\n",
        "# Define training and validation directories\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# General data augmentation for binary classification\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    brightness_range=[0.9, 1.1],\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'  # Use 50% of the validation set for actual validation during training\n",
        ")\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation',  # Use the remaining 50% as a test set\n",
        "    shuffle=False  # Important: do not shuffle to keep labels aligned for evaluation\n",
        ")\n",
        "# Define the model for binary classification\n",
        "model = Sequential([\n",
        "    EfficientNetB5(input_shape=(224, 224, 3), include_top=False, weights='imagenet'),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.8),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_filepath = '/content/drive/MyDrive/efficientnet_checkpoints/best_weights.weights.h5'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return float(lr)\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))\n",
        "\n",
        "lr_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=28,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr, lr_callback]\n",
        ")\n",
        "\n",
        "# Load the best model\n",
        "#best_model = tf.keras.models.load_model(checkpoint_filepath)\n",
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "model.save('/content/drive/MyDrive/efficientnet_checkpoints/best_model.h5')\n",
        "# Evaluate the best model\n",
        "loss, accuracy = model.evaluate(validation_generator, verbose=0)\n",
        "print(f'Validation loss: {loss}, Validation accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Generate predictions on the test set\n",
        "test_steps = test_generator.samples // test_generator.batch_size\n",
        "y_pred = model.predict(test_generator, steps=test_steps, verbose=1)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "y_true = test_generator.classes[:len(y_pred_labels)]\n",
        "\n",
        "# Compute the confusion matrix for the test set\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_labels)\n",
        "class_names = ['benign', 'malignant']\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Test Set')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report for the test set\n",
        "report = classification_report(y_true, y_pred_labels, target_names=class_names)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk0iUsstFkB8",
        "outputId": "9a58c468-dcc3-4124-fe1f-10037dcb1357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8311 images belonging to 2 classes.\n",
            "Found 791 images belonging to 2 classes.\n",
            "Found 791 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb5_notop.h5\n",
            "\u001b[1m115263384/115263384\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.9800 - loss: 0.0727 \n",
            "Epoch 1: val_loss improved from inf to 7.17775, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4468s\u001b[0m 16s/step - accuracy: 0.9800 - loss: 0.0727 - val_accuracy: 0.3300 - val_loss: 7.1777 - learning_rate: 1.0000e-04\n",
            "Epoch 2/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9874 - loss: 0.0490\n",
            "Epoch 2: val_loss improved from 7.17775 to 1.95112, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 1s/step - accuracy: 0.9874 - loss: 0.0490 - val_accuracy: 0.3515 - val_loss: 1.9511 - learning_rate: 1.0000e-04\n",
            "Epoch 3/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9895 - loss: 0.0417\n",
            "Epoch 3: val_loss improved from 1.95112 to 0.49520, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 1s/step - accuracy: 0.9895 - loss: 0.0417 - val_accuracy: 0.7649 - val_loss: 0.4952 - learning_rate: 1.0000e-04\n",
            "Epoch 4/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9906 - loss: 0.0396\n",
            "Epoch 4: val_loss did not improve from 0.49520\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 1s/step - accuracy: 0.9906 - loss: 0.0396 - val_accuracy: 0.7674 - val_loss: 0.9904 - learning_rate: 1.0000e-04\n",
            "Epoch 5/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9894 - loss: 0.0407\n",
            "Epoch 5: val_loss did not improve from 0.49520\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 1s/step - accuracy: 0.9894 - loss: 0.0407 - val_accuracy: 0.6865 - val_loss: 1.0118 - learning_rate: 1.0000e-04\n",
            "Epoch 6/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0343\n",
            "Epoch 6: val_loss did not improve from 0.49520\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0343 - val_accuracy: 0.4703 - val_loss: 4.3166 - learning_rate: 1.0000e-04\n",
            "Epoch 7/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9909 - loss: 0.0369\n",
            "Epoch 7: val_loss did not improve from 0.49520\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.9909 - loss: 0.0369 - val_accuracy: 0.7699 - val_loss: 0.7820 - learning_rate: 1.0000e-04\n",
            "Epoch 8/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9940 - loss: 0.0270\n",
            "Epoch 8: val_loss improved from 0.49520 to 0.36452, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 1s/step - accuracy: 0.9940 - loss: 0.0270 - val_accuracy: 0.8812 - val_loss: 0.3645 - learning_rate: 1.0000e-04\n",
            "Epoch 9/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9933 - loss: 0.0274\n",
            "Epoch 9: val_loss improved from 0.36452 to 0.07980, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.9933 - loss: 0.0273 - val_accuracy: 0.9848 - val_loss: 0.0798 - learning_rate: 1.0000e-04\n",
            "Epoch 10/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.0215\n",
            "Epoch 10: val_loss did not improve from 0.07980\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.0215 - val_accuracy: 0.4109 - val_loss: 2.3056 - learning_rate: 1.0000e-04\n",
            "Epoch 11/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9913 - loss: 0.0341\n",
            "Epoch 11: val_loss did not improve from 0.07980\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.9913 - loss: 0.0341 - val_accuracy: 0.7661 - val_loss: 1.0627 - learning_rate: 9.0484e-05\n",
            "Epoch 12/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9964 - loss: 0.0191\n",
            "Epoch 12: val_loss did not improve from 0.07980\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.9964 - loss: 0.0191 - val_accuracy: 0.8129 - val_loss: 0.5246 - learning_rate: 8.1873e-05\n",
            "Epoch 13/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9962 - loss: 0.0165\n",
            "Epoch 13: val_loss did not improve from 0.07980\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.9962 - loss: 0.0165 - val_accuracy: 0.8900 - val_loss: 0.2868 - learning_rate: 7.4082e-05\n",
            "Epoch 14/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9973 - loss: 0.0146\n",
            "Epoch 14: val_loss did not improve from 0.07980\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 1s/step - accuracy: 0.9973 - loss: 0.0146 - val_accuracy: 0.9646 - val_loss: 0.1186 - learning_rate: 3.3516e-05\n",
            "Epoch 15/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0128\n",
            "Epoch 15: val_loss improved from 0.07980 to 0.05035, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0128 - val_accuracy: 0.9874 - val_loss: 0.0503 - learning_rate: 3.0327e-05\n",
            "Epoch 16/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9989 - loss: 0.0108\n",
            "Epoch 16: val_loss did not improve from 0.05035\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - accuracy: 0.9989 - loss: 0.0108 - val_accuracy: 0.9558 - val_loss: 0.1316 - learning_rate: 2.7441e-05\n",
            "Epoch 17/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.0158\n",
            "Epoch 17: val_loss improved from 0.05035 to 0.04656, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.0158 - val_accuracy: 0.9874 - val_loss: 0.0466 - learning_rate: 2.4829e-05\n",
            "Epoch 18/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9980 - loss: 0.0106\n",
            "Epoch 18: val_loss did not improve from 0.04656\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.9980 - loss: 0.0106 - val_accuracy: 0.9798 - val_loss: 0.0816 - learning_rate: 2.2466e-05\n",
            "Epoch 19/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9970 - loss: 0.0211\n",
            "Epoch 19: val_loss improved from 0.04656 to 0.03657, saving model to /content/drive/MyDrive/efficientnet_checkpoints/best_model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 1s/step - accuracy: 0.9970 - loss: 0.0210 - val_accuracy: 0.9912 - val_loss: 0.0366 - learning_rate: 2.0328e-05\n",
            "Epoch 20/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9989 - loss: 0.0099\n",
            "Epoch 20: val_loss did not improve from 0.03657\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.9989 - loss: 0.0099 - val_accuracy: 0.9886 - val_loss: 0.0366 - learning_rate: 1.8394e-05\n",
            "Epoch 21/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0087\n",
            "Epoch 21: val_loss did not improve from 0.03657\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0087 - val_accuracy: 0.9671 - val_loss: 0.1152 - learning_rate: 1.6644e-05\n",
            "Epoch 22/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9983 - loss: 0.0107\n",
            "Epoch 22: val_loss did not improve from 0.03657\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9836 - val_loss: 0.0624 - learning_rate: 1.5060e-05\n",
            "Epoch 23/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9981 - loss: 0.0107\n",
            "Epoch 23: val_loss did not improve from 0.03657\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.9981 - loss: 0.0107 - val_accuracy: 0.9836 - val_loss: 0.0651 - learning_rate: 1.3627e-05\n",
            "Epoch 24/27\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9984 - loss: 0.0106\n",
            "Epoch 24: val_loss did not improve from 0.03657\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 1s/step - accuracy: 0.9984 - loss: 0.0106 - val_accuracy: 0.9836 - val_loss: 0.0569 - learning_rate: 6.1649e-06\n",
            "Epoch 25/27\n",
            "\u001b[1m 83/260\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:27\u001b[0m 1s/step - accuracy: 0.9975 - loss: 0.0100"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB5\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Define base directory\n",
        "base_dir = '/content/drive/MyDrive/breakhis/BreaKHis_v1/histology_slides/breast'\n",
        "\n",
        "# Define training and validation directories\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# General data augmentation for binary classification\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    brightness_range=[0.9, 1.1],\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'  # Use 50% of the validation set for actual validation during training\n",
        ")\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation',  # Use the remaining 50% as a test set\n",
        "    shuffle=False  # Important: do not shuffle to keep labels aligned for evaluation\n",
        ")\n",
        "\n",
        "# Recreate the model architecture\n",
        "model = Sequential([\n",
        "    EfficientNetB5(input_shape=(224, 224, 3), include_top=False, weights='imagenet'),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.8),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "])\n",
        "\n",
        "# Build the model by passing in a dummy input shape\n",
        "model.build((None, 224, 224, 3))\n",
        "# Load the weights from the saved model\n",
        "model.load_weights('/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras')\n",
        "\n",
        "# Re-compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint_filepath = '/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return float(lr)\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))\n",
        "\n",
        "lr_callback = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Continue training the model\n",
        "remaining_epochs = 27  # Adjust based on how many epochs you want to continue\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=remaining_epochs,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[checkpoint, early_stopping, reduce_lr, lr_callback]\n",
        ")\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "val_loss, val_accuracy = best_model.evaluate(validation_generator, verbose=0)\n",
        "print(f'Validation loss: {val_loss}, Validation accuracy: {val_accuracy * 100:.2f}%')\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_loss, test_accuracy = best_model.evaluate(test_generator, verbose=0)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Generate predictions on the test set\n",
        "test_steps = test_generator.samples // test_generator.batch_size\n",
        "y_pred = best_model.predict(test_generator, steps=test_steps, verbose=1)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "y_true = test_generator.classes[:len(y_pred_labels)]\n",
        "\n",
        "# Compute the confusion matrix for the test set\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_labels)\n",
        "class_names = ['benign', 'malignant']\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Test Set')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report for the test set\n",
        "report = classification_report(y_true, y_pred_labels, target_names=class_names)\n",
        "print(report)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB5\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define base directory for test data\n",
        "base_dir = '/content/drive/MyDrive/breakhis/BreaKHis_v1/histology_slides/breast'\n",
        "val_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Test data augmentation\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
        "\n",
        "# Load the test set\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation',  # Use the remaining 50% as the test set\n",
        "    shuffle=False  # Important: do not shuffle to keep labels aligned for evaluation\n",
        ")\n",
        "# Recreate the model architecture\n",
        "model = Sequential([\n",
        "    EfficientNetB5(input_shape=(224, 224, 3), include_top=False, weights='imagenet'),\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.8),\n",
        "    Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "])\n",
        "\n",
        "# Build the model\n",
        "model.build((None, 224, 224, 3))\n",
        "\n",
        "# Load the saved weights instead of the full model\n",
        "model.load_weights('/content/drive/MyDrive/efficientnet_checkpoints/best_model.keras')\n",
        "\n",
        "# Compile the model again\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, verbose=0)\n",
        "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "# Generate predictions on the test set\n",
        "#test_steps = test_generator.samples // test_generator.batch_size\n",
        "#y_pred = model.predict(test_generator, steps=test_steps, verbose=1)\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "y_true = test_generator.classes[:len(y_pred_labels)]\n",
        "\n",
        "# Compute the confusion matrix for the test set\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_labels)\n",
        "class_names = ['benign', 'malignant']\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 34})\n",
        "plt.xlabel('Predicted Label',fontsize=18)\n",
        "plt.ylabel('True Label',fontsize=18)\n",
        "plt.title('Confusion Matrix - Test Set',fontsize=18)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Print classification report for the test set\n",
        "report = classification_report(y_true, y_pred_labels, target_names=class_names)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jvXQfoF_e7yO",
        "outputId": "5b440e24-4925-4893-c550-2788d3cdc3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 791 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.06346616894006729, Test accuracy: 98.23%\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 999ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      0.95      0.97       248\n",
            "   malignant       0.98      1.00      0.99       543\n",
            "\n",
            "    accuracy                           0.98       791\n",
            "   macro avg       0.98      0.97      0.98       791\n",
            "weighted avg       0.98      0.98      0.98       791\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9/F+2QlG+GjRJUUz4rqLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}